{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eef3ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow keras opencv-python matplotlib numpy pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e3cc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(\"fer2013.csv\")\n",
    "\n",
    "# Mapping labels to emotions\n",
    "emotion_labels = {0:'Angry', 1:'Disgust', 2:'Fear', 3:'Happy', 4:'Sad', 5:'Surprise', 6:'Neutral'}\n",
    "\n",
    "# Extract pixels and labels\n",
    "pixels = data['pixels'].tolist()\n",
    "faces = []\n",
    "for pixel_sequence in pixels:\n",
    "    face = np.array([int(pixel) for pixel in pixel_sequence.split()]).reshape(48,48)\n",
    "    faces.append(face.astype('float32') / 255.0)  # Normalize\n",
    "\n",
    "faces = np.expand_dims(np.array(faces), -1)  # Add channel dimension\n",
    "labels = to_categorical(data['emotion'], num_classes=7)\n",
    "\n",
    "# Split data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(faces, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873a5a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(48,48,1)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2,2),\n",
    "    \n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2,2),\n",
    "    \n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2,2),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2066a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=30,\n",
    "    batch_size=64\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b035f1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e706081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load pre-trained Haar Cascade for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# Start webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces_detected = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    for (x,y,w,h) in faces_detected:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_gray = cv2.resize(roi_gray, (48,48))\n",
    "        roi = roi_gray.astype('float32') / 255.0\n",
    "        roi = np.expand_dims(roi, axis=0)\n",
    "        roi = np.expand_dims(roi, -1)\n",
    "        \n",
    "        prediction = model.predict(roi)\n",
    "        maxindex = int(np.argmax(prediction))\n",
    "        emotion = emotion_labels[maxindex]\n",
    "        \n",
    "        cv2.rectangle(frame, (x,y), (x+w, y+h), (0,255,0), 2)\n",
    "        cv2.putText(frame, emotion, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "    \n",
    "    cv2.imshow('Emotion Recognition', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
